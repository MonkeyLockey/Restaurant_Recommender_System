import sys
from datetime import datetime
import os
import logging  # æ–°å¢å°å…¥

# å¾ scraper å¥—ä»¶ä¸­å°å…¥æ ¸å¿ƒé‚è¼¯
from scraper.core import RestaurantScraper, get_location_config


def run_scraper_main():
    API_KEY = os.getenv("GOOGLE_MAPS_API_KEY")  # Load from environment variable

    history_data_filename = "birmingham_restaurants_history.csv"
    current_timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_filename = f"birmingham_restaurants_{current_timestamp}.csv"
    log_filename = f"birmingham_scraper_log_{current_timestamp}.txt"  # æ–°å¢: æ—¥èªŒæª”æ¡ˆå

    # --- é…ç½®æ—¥èªŒç³»çµ± ---
    # å‰µå»ºä¸€å€‹ logger ç‰©ä»¶
    logger = logging.getLogger(__name__)
    logger.setLevel(logging.INFO)  # è¨­å®šæœ€ä½æ—¥èªŒç´šåˆ¥ç‚º INFO

    # å‰µå»ºä¸€å€‹æª”æ¡ˆè™•ç†å™¨ï¼Œç”¨æ–¼å¯«å…¥æ—¥èªŒæª”æ¡ˆ
    file_handler = logging.FileHandler(log_filename, encoding='utf-8')
    file_handler.setLevel(logging.INFO)  # æª”æ¡ˆè™•ç†å™¨ä¹Ÿè¨­å®šç‚º INFO ç´šåˆ¥

    # å‰µå»ºä¸€å€‹æ§åˆ¶å°è™•ç†å™¨ï¼Œç”¨æ–¼è¼¸å‡ºåˆ°æ§åˆ¶å°
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setLevel(logging.INFO)  # æ§åˆ¶å°è™•ç†å™¨ä¹Ÿè¨­å®šç‚º INFO ç´šåˆ¥

    # å®šç¾©æ—¥èªŒæ ¼å¼
    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
    file_handler.setFormatter(formatter)
    console_handler.setFormatter(formatter)

    # å°‡è™•ç†å™¨æ·»åŠ åˆ° logger
    logger.addHandler(file_handler)
    logger.addHandler(console_handler)

    # æ›¿æ›å…§å»ºçš„ print å‡½å¼ï¼Œè®“æ‰€æœ‰ print è¼¸å‡ºä¹Ÿé€šé logger.info
    # æ³¨æ„: é€™æœƒå½±éŸ¿æ‰€æœ‰ print èªå¥ï¼ŒåŒ…æ‹¬ç¬¬ä¸‰æ–¹åº«çš„ print
    # ä½†å°æ–¼æ‚¨çš„ç¨‹å¼ç¢¼ï¼Œæˆ‘å€‘å°‡ç›´æ¥ä½¿ç”¨ logger.info
    # sys.stdout = file_handler.stream # ä¸æ¨è–¦ç›´æ¥æ›¿æ› sys.stdoutï¼Œå› ç‚ºæœƒå½±éŸ¿ input()

    # --------------------

    # å‰µå»ºçˆ¬èŸ²å¯¦ä¾‹
    scraper = RestaurantScraper(API_KEY, existing_csv_filename=history_data_filename)

    locations = get_location_config()

    logger.info("=== æœå°‹ç¯„åœè¨­å®š ===")
    logger.info("ğŸ¯ ä½¿ç”¨ç¶²æ ¼æœå°‹æ³•çªç ´ 60 å®¶åœ°é»é™åˆ¶")

    search_types = ["restaurant", "cafe", "bar", "pub", "takeaway", "fast_food"]
    logger.info(f"ğŸ” å°‡æœå°‹ä»¥ä¸‹é¡å‹: {', '.join(search_types)}")

    logger.info("ğŸ“ Birmingham City Centre åˆ†ç‚ºå¤šå€‹é‡ç–Šå€åŸŸ:")
    city_centre_areas = [loc for loc in locations if
                         "Birmingham" in loc['name'] and "University" not in loc['name'] and "Selly Oak" not in loc[
                             'name'] and "Edgbaston" not in loc['name']]
    for i, location in enumerate(city_centre_areas, 1):
        logger.info(f"   {i}. {location['description']} - {location['radius'] / 1000}km åŠå¾‘")

    logger.info("\nğŸ“ University of Birmingham åŠå‘¨é‚Šå€åŸŸ:")
    uob_areas = [loc for loc in locations if
                 "University" in loc['name'] or "Selly Oak" in loc['name'] or "Edgbaston" in loc['name']]
    for i, location in enumerate(uob_areas, 1):
        logger.info(f"   {i}. {location['description']} - {location['radius'] / 1000}km åŠå¾‘")

    logger.info(f"\nğŸ’¡ ç¸½å…± {len(locations)} å€‹æœå°‹å€åŸŸï¼Œé è¨ˆå¯ç²å–å¤§é‡ç¨ç‰¹åœ°é»")
    logger.info("ğŸ”„ è‡ªå‹•å»é‡åŠŸèƒ½å°‡ç§»é™¤é‡è¤‡çš„åœ°é»ï¼Œç¯€çœAPIè²»ç”¨")
    logger.info("")  # ç‚ºäº†æ—¥èªŒæ’ç‰ˆ

    logger.info("\n=== èªè¨€è¨­å®š ===")
    # input() å‡½å¼ç„¡æ³•è¢« logging æ¨¡çµ„æ•ç²ï¼Œæ‰€ä»¥é€™è£¡ä»ç„¶ä½¿ç”¨ input()
    language_choice = input("é¸æ“‡è©•è«–èªè¨€:\n1. åŸæ–‡è©•è«– (ä¸ç¿»è­¯)\n2. è‹±æ–‡ç¿»è­¯\nè«‹é¸æ“‡ (1/2): ")
    use_original_language = (language_choice == '1')

    if use_original_language:
        logger.info("å°‡ç²å–åŸæ–‡è©•è«–")
    else:
        logger.info("å°‡ç²å–è‹±æ–‡ç¿»è­¯è©•è«–")

    num_locations = len(locations)
    num_search_types = len(search_types)
    total_max_restaurants_per_search = sum(loc['limit'] for loc in locations)

    estimated_geocode_calls = num_locations
    estimated_nearby_search_calls = num_locations * num_search_types * 3

    estimated_place_details_calls_max = total_max_restaurants_per_search
    estimated_place_details_calls_realistic = int(num_locations * 30 * (num_search_types / 2))

    total_estimated_calls_worst_case = estimated_geocode_calls + estimated_nearby_search_calls + estimated_place_details_calls_max
    total_estimated_calls_realistic = estimated_geocode_calls + estimated_nearby_search_calls + estimated_place_details_calls_realistic

    logger.info("=== APIä½¿ç”¨èªªæ˜ ===")
    logger.info("âš ï¸  Google Places API é™åˆ¶:")
    logger.info("    - æ¯å€‹ Places Nearby Search (å–®ä¸€é¡å‹) æœ€å¤šè¿”å› 60 å®¶åœ°é» (åˆ† 3 é ï¼Œæ¯é  20 å®¶)")
    logger.info("    - æœ€å¤§æœå°‹åŠå¾‘: 50å…¬é‡Œ")
    logger.info(f"\nğŸ“Š é ä¼°APIèª¿ç”¨ (å…± {num_locations} å€‹æœå°‹å€åŸŸï¼Œ{num_search_types} ç¨®åœ°é»é¡å‹):")
    logger.info(f"- Geocoding API: {estimated_geocode_calls} æ¬¡")
    logger.info(
        f"- Places Nearby Search: æœ€å¤š {estimated_nearby_search_calls} æ¬¡ (æ¯å€‹åœ°é» * æ¯å€‹é¡å‹ * æœ€å¤š 3 æ¬¡ï¼ŒåŒ…æ‹¬åˆ†é )")
    logger.info(f"- Place Details: é ä¼° {estimated_place_details_calls_realistic} æ¬¡ (å»é‡å¾Œ)")
    logger.info(f"  â””â”€ ç†è«–æœ€å¤§å€¼: {estimated_place_details_calls_max} æ¬¡ (ç„¡é‡è¤‡æƒ…æ³)")
    logger.info(f"\nğŸ’° é ä¼°è²»ç”¨ (åŸºæ–¼ $0.017/æ¬¡ Nearby Search æˆ– Place Details):")
    logger.info(f"- ç¾å¯¦é ä¼°: ${total_estimated_calls_realistic * 0.017:.2f} USD")
    logger.info(f"- æœ€å£æƒ…æ³: ${total_estimated_calls_worst_case * 0.017:.2f} USD")
    logger.info(f"\nğŸ“ æ³¨æ„:")
    logger.info(f"- ä½¿ç”¨ç¶²æ ¼æœå°‹æ³•ï¼Œé è¨ˆå¯ç²å–å¤§é‡ç¨ç‰¹åœ°é»")
    logger.info(f"- é‡ç–Šå€åŸŸå’Œä¸åŒé¡å‹çš„é‡è¤‡åœ°é»æœƒè‡ªå‹•å»é‡ï¼Œæœ‰æ•ˆç¯€çœAPIè²»ç”¨")
    logger.info(f"- å¾ '{history_data_filename}' åŠ è¼‰æ­·å²æ•¸æ“šé€²è¡Œè·¨é‹è¡Œå»é‡")

    confirm = input("\næ˜¯å¦ç¹¼çºŒåŸ·è¡Œ? (y/n): ")  # input() ä»ç„¶éœ€è¦ç›´æ¥è¼¸å‡ºåˆ°æ§åˆ¶å°
    if confirm.lower() != 'y':
        logger.info("ç¨‹å¼å·²å–æ¶ˆ")
        return

    logger.info("\né–‹å§‹ç¶²æ ¼æœå°‹åœ°é»...")
    logger.info("=" * 50)

    for i, location_config in enumerate(locations, 1):
        logger.info(f"\nğŸ” [{i}/{len(locations)}] æœå°‹å€åŸŸ: {location_config['description']}")
        logger.info(f"ğŸ“ åœ°é»: {location_config['name']}")
        logger.info(f"ğŸ“ åŠå¾‘: {location_config['radius'] / 1000}km")

        before_count = len(scraper.processed_place_ids)
        scraper.search_restaurants(
            location=location_config['name'],
            radius=location_config['radius'],
            limit=location_config['limit'],
            use_original_language=use_original_language,
            place_types=search_types
        )
        after_count = len(scraper.processed_place_ids)
        new_restaurants_added_in_this_area = after_count - before_count

        logger.info(f"âœ… æ­¤å€åŸŸæ–°å¢ {new_restaurants_added_in_this_area} å®¶åœ°é»")
        logger.info(f"ğŸ“Š ç›®å‰ç¸½è¨ˆ: {after_count} å®¶ç¨ç‰¹åœ°é»")
        logger.info("-" * 30)

    scraper.print_summary()  # é€™å€‹æ–¹æ³•å…§éƒ¨ä»ç„¶ä½¿ç”¨ printï¼Œä½ å¯ä»¥é¸æ“‡ä¿®æ”¹å®ƒæˆ–è®“å®ƒä¿æŒåŸæ¨£
    scraper.save_to_csv(output_filename)

    logger.info(f"\nğŸ¯ ç¶²æ ¼æœå°‹ç­–ç•¥æˆåŠŸå®Œæˆï¼")
    logger.info(f"ğŸ“ è³‡æ–™å·²ä¿å­˜è‡³: {output_filename}")
    logger.info(f"ğŸ’¡ æç¤º: å°‡ '{output_filename}' é‡å‘½åç‚º '{history_data_filename}' ä»¥ä¾›ä¸‹æ¬¡å»é‡ä½¿ç”¨")

    logger.info(f"\nğŸ† æœ€çµ‚çµ±è¨ˆ")
    logger.info(f"ğŸ“ å¯¦éš›APIèª¿ç”¨æ¬¡æ•¸: {scraper.api_call_count}")
    logger.info(f"ğŸ’° å¯¦éš›è²»ç”¨: ${scraper.api_call_count * 0.017:.2f} USD")
    logger.info(f"ğŸª ç²å–åœ°é»ç¸½æ•¸ (åŒ…å«é‡è¤‡æ¢ç›®): {len(scraper.restaurants_data)} å®¶")
    logger.info(f"ğŸ”‘ ç¨ç‰¹åœ°é»ç¸½æ•¸: {len(scraper.processed_place_ids)} å®¶")
    logger.info(f"ğŸ¯ è¦†è“‹Birminghamå…¨å€åŸŸ: âœ…")

    logger.info(f"\nğŸ“ˆ æœå°‹æ•ˆæœåˆ†æ:")
    logger.info(f"- é æœŸæœ€å¤§åœ°é»æ•¸ (æ‰€æœ‰æœå°‹å€åŸŸçš„ä¸Šé™ç¸½å’Œ): {total_max_restaurants_per_search} å®¶")
    logger.info(f"- å¯¦éš›ç²å–ç¨ç‰¹åœ°é»æ•¸: {len(scraper.processed_place_ids)} å®¶")
    efficiency = (
                             len(scraper.processed_place_ids) / total_max_restaurants_per_search) * 100 if total_max_restaurants_per_search > 0 else 0
    logger.info(f"- æœå°‹æ•ˆç‡ (ç¨ç‰¹åœ°é»ä½”ç†è«–æœ€å¤§å€¼): {efficiency:.1f}%")
    if efficiency < 50:
        logger.info("ğŸ’¡ æ•ˆç‡è¼ƒä½å¯èƒ½æ˜¯å› ç‚ºå€åŸŸé‡ç–Šå°è‡´å¤§é‡é‡è¤‡ï¼Œé€™æ˜¯æ­£å¸¸ç¾è±¡ï¼Œå»é‡åŠŸèƒ½å·²ç¯€çœè²»ç”¨ã€‚")
    else:
        logger.info("ğŸ‰ é«˜æ•ˆç‡æœå°‹ï¼ŒæˆåŠŸç²å–å¤§é‡ç¨ç‰¹åœ°é»ï¼")


if __name__ == "__main__":
    run_scraper_main()
