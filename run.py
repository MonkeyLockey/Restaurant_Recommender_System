import sys
from datetime import datetime
import os

# å¾ scraper å¥—ä»¶ä¸­å°å…¥æ ¸å¿ƒé‚è¼¯
from scraper.core import RestaurantScraper, get_location_config


def run_scraper_main():
    API_KEY = os.getenv("GOOGLE_MAPS_API_KEY")  # Load from environment variable

    history_data_filename = "birmingham_restaurants_history.csv"
    current_timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_filename = f"birmingham_restaurants_{current_timestamp}.csv"

    scraper = RestaurantScraper(API_KEY, existing_csv_filename=history_data_filename)

    locations = get_location_config()

    # --- æ–°å¢: å®šç¾©è¦æœå°‹çš„åœ°é»é¡å‹åˆ—è¡¨ ---
    search_types = ["restaurant", "cafe", "bar", "pub", "takeaway", "fast_food"]  # æ‚¨å¯ä»¥æ ¹æ“šéœ€è¦èª¿æ•´é€™äº›é¡å‹
    # ------------------------------------

    print("=== æœå°‹ç¯„åœè¨­å®š ===")
    print("ğŸ¯ ä½¿ç”¨ç¶²æ ¼æœå°‹æ³•çªç ´ 60 å®¶é¤å»³é™åˆ¶")
    print(f"ğŸ” å°‡æœå°‹ä»¥ä¸‹é¡å‹: {', '.join(search_types)}")  # é¡¯ç¤ºæœå°‹é¡å‹
    print("ğŸ“ Birmingham City Centre åˆ†ç‚ºå¤šå€‹é‡ç–Šå€åŸŸ:")
    city_centre_areas = [loc for loc in locations if
                         "Birmingham" in loc['name'] and "University" not in loc['name'] and "Selly Oak" not in loc[
                             'name'] and "Edgbaston" not in loc['name']]
    for i, location in enumerate(city_centre_areas, 1):
        print(f"   {i}. {location['description']} - {location['radius'] / 1000}km åŠå¾‘")

    print("\nğŸ“ University of Birmingham åŠå‘¨é‚Šå€åŸŸ:")
    uob_areas = [loc for loc in locations if
                 "University" in loc['name'] or "Selly Oak" in loc['name'] or "Edgbaston" in loc['name']]
    for i, location in enumerate(uob_areas, 1):
        print(f"   {i}. {location['description']} - {location['radius'] / 1000}km åŠå¾‘")

    print(f"\nğŸ’¡ ç¸½å…± {len(locations)} å€‹æœå°‹å€åŸŸï¼Œé è¨ˆå¯ç²å–å¤§é‡ç¨ç‰¹åœ°é»")  # æ›´æ–°æè¿°
    print("ğŸ”„ è‡ªå‹•å»é‡åŠŸèƒ½å°‡ç§»é™¤é‡è¤‡çš„åœ°é»ï¼Œç¯€çœAPIè²»ç”¨")  # æ›´æ–°æè¿°
    print()

    print("\n=== èªè¨€è¨­å®š ===")
    language_choice = input("é¸æ“‡è©•è«–èªè¨€:\n1. åŸæ–‡è©•è«– (ä¸ç¿»è­¯)\n2. è‹±æ–‡ç¿»è­¯\nè«‹é¸æ“‡ (1/2): ")
    use_original_language = (language_choice == '1')

    if use_original_language:
        print("å°‡ç²å–åŸæ–‡è©•è«–")
    else:
        print("å°‡ç²å–è‹±æ–‡ç¿»è­¯è©•è«–")

    num_locations = len(locations)
    # --- æ›´æ–° API é ä¼°: æ¯å€‹åœ°é»æœƒå°æ¯å€‹é¡å‹é€²è¡Œ Places Nearby Search ---
    num_search_types = len(search_types)
    total_max_restaurants_per_search = sum(loc['limit'] for loc in locations)  # é€™è£¡çš„ limit ä»æ˜¯å–®ä¸€åœ°é»çš„ç¸½ç¨ç‰¹ä¸Šé™

    estimated_geocode_calls = num_locations
    estimated_nearby_search_calls = num_locations * num_search_types * 3  # æ¯å€‹åœ°é» * æ¯å€‹é¡å‹ * æœ€å¤š 3 é 

    # Place Details çš„å‘¼å«æ¬¡æ•¸å–æ±ºæ–¼å»é‡å¾Œçš„å¯¦éš›æ•¸é‡ï¼Œç†è«–æœ€å¤§å€¼æ˜¯æ‰€æœ‰åœ°é»çš„ limit ç¸½å’Œã€‚
    # ç¾å¯¦é ä¼°å¯ä»¥åŸºæ–¼ç¸½åœ°é»æ•¸å’Œæ¯å€‹åœ°é»é è¨ˆè²¢ç»çš„ç¨ç‰¹åœ°é»æ•¸ã€‚
    estimated_place_details_calls_max = total_max_restaurants_per_search  # ç†è«–æœ€å¤§å€¼ (æ‰€æœ‰åœ°é»éƒ½è¿”å›æ»¿60å®¶ä¸”å®Œå…¨ä¸é‡è¤‡)
    estimated_place_details_calls_realistic = int(num_locations * 30 * (num_search_types / 2))  # ç²—ç•¥ä¼°è¨ˆï¼Œå¯èƒ½æ›´å¤šç¨ç‰¹åœ°é»

    total_estimated_calls_worst_case = estimated_geocode_calls + estimated_nearby_search_calls + estimated_place_details_calls_max
    total_estimated_calls_realistic = estimated_geocode_calls + estimated_nearby_search_calls + estimated_place_details_calls_realistic

    print("=== APIä½¿ç”¨èªªæ˜ ===")
    print("âš ï¸  Google Places API é™åˆ¶:")
    print("    - æ¯å€‹ Places Nearby Search (å–®ä¸€é¡å‹) æœ€å¤šè¿”å› 60 å®¶åœ°é» (åˆ† 3 é ï¼Œæ¯é  20 å®¶)")
    print("    - æœ€å¤§æœå°‹åŠå¾‘: 50å…¬é‡Œ")
    print(f"\nğŸ“Š é ä¼°APIèª¿ç”¨ (å…± {num_locations} å€‹æœå°‹å€åŸŸï¼Œ{num_search_types} ç¨®åœ°é»é¡å‹):")
    print(f"- Geocoding API: {estimated_geocode_calls} æ¬¡")
    print(f"- Places Nearby Search: æœ€å¤š {estimated_nearby_search_calls} æ¬¡ (æ¯å€‹åœ°é» * æ¯å€‹é¡å‹ * æœ€å¤š 3 æ¬¡ï¼ŒåŒ…æ‹¬åˆ†é )")
    print(f"- Place Details: é ä¼° {estimated_place_details_calls_realistic} æ¬¡ (å»é‡å¾Œ)")
    print(f"  â””â”€ ç†è«–æœ€å¤§å€¼: {estimated_place_details_calls_max} æ¬¡ (ç„¡é‡è¤‡æƒ…æ³)")
    print(f"\nğŸ’° é ä¼°è²»ç”¨ (åŸºæ–¼ $0.017/æ¬¡ Nearby Search æˆ– Place Details):")
    print(f"- ç¾å¯¦é ä¼°: ${total_estimated_calls_realistic * 0.017:.2f} USD")
    print(f"- æœ€å£æƒ…æ³: ${total_estimated_calls_worst_case * 0.017:.2f} USD")
    print(f"\nğŸ“ æ³¨æ„:")
    print(f"- ä½¿ç”¨ç¶²æ ¼æœå°‹æ³•ï¼Œé è¨ˆå¯ç²å–å¤§é‡ç¨ç‰¹åœ°é»")
    print(f"- é‡ç–Šå€åŸŸå’Œä¸åŒé¡å‹çš„é‡è¤‡åœ°é»æœƒè‡ªå‹•å»é‡ï¼Œæœ‰æ•ˆç¯€çœAPIè²»ç”¨")
    print(f"- å¾ '{history_data_filename}' åŠ è¼‰æ­·å²æ•¸æ“šé€²è¡Œè·¨é‹è¡Œå»é‡")

    confirm = input("\næ˜¯å¦ç¹¼çºŒåŸ·è¡Œ? (y/n): ")
    if confirm.lower() != 'y':
        print("ç¨‹å¼å·²å–æ¶ˆ")
        return

    print("\né–‹å§‹ç¶²æ ¼æœå°‹åœ°é»...")  # æ›´æ–°æè¿°
    print("=" * 50)

    for i, location_config in enumerate(locations, 1):
        print(f"\nğŸ” [{i}/{len(locations)}] æœå°‹å€åŸŸ: {location_config['description']}")
        print(f"ğŸ“ åœ°é»: {location_config['name']}")
        print(f"ğŸ“ åŠå¾‘: {location_config['radius'] / 1000}km")

        # --- æ–°å¢ try-except å¡Šä¾†æ•ç² search_restaurants å‘¼å«æ™‚å¯èƒ½ç™¼ç”Ÿçš„éŒ¯èª¤ ---
        try:
            before_count = len(scraper.processed_place_ids)
            scraper.search_restaurants(
                location=location_config['name'],
                radius=location_config['radius'],
                limit=location_config['limit'],
                use_original_language=use_original_language,
                place_types=search_types
            )
            after_count = len(scraper.processed_place_ids)
            new_restaurants_added_in_this_area = after_count - before_count

            print(f"âœ… æ­¤å€åŸŸæ–°å¢ {new_restaurants_added_in_this_area} å®¶åœ°é»")
            print(f"ğŸ“Š ç›®å‰ç¸½è¨ˆ: {after_count} å®¶ç¨ç‰¹åœ°é»")
            print("-" * 30)
        except Exception as e:
            print(f"âŒ éŒ¯èª¤: åœ¨è™•ç†å€åŸŸ '{location_config['description']}' æ™‚ç™¼ç”Ÿå•é¡Œ: {e}")
            print("è«‹æª¢æŸ¥ API Keyã€ç¶²è·¯é€£ç·šæˆ–è©²å€åŸŸçš„è¨­å®šã€‚ç¨‹å¼å°‡å˜—è©¦ç¹¼çºŒè™•ç†ä¸‹ä¸€å€‹å€åŸŸã€‚")
            # é€™è£¡é¸æ“‡ `continue`ï¼Œè®“ç¨‹å¼å³ä½¿é‡åˆ°éŒ¯èª¤ä¹Ÿèƒ½å˜—è©¦è™•ç†å…¶ä»–å€åŸŸ
            continue
            # --------------------------------------------------------------------

    scraper.print_summary()
    scraper.save_to_csv(output_filename)

    print(f"\nğŸ¯ ç¶²æ ¼æœå°‹ç­–ç•¥æˆåŠŸå®Œæˆï¼")
    print(f"ğŸ“ è³‡æ–™å·²ä¿å­˜è‡³: {output_filename}")
    print(f"ğŸ’¡ æç¤º: å°‡ '{output_filename}' é‡å‘½åç‚º '{history_data_filename}' ä»¥ä¾›ä¸‹æ¬¡å»é‡ä½¿ç”¨")

    print(f"\nğŸ† æœ€çµ‚çµ±è¨ˆ")
    print(f"ğŸ“ å¯¦éš›APIèª¿ç”¨æ¬¡æ•¸: {scraper.api_call_count}")
    print(f"ğŸ’° å¯¦éš›è²»ç”¨: ${scraper.api_call_count * 0.017:.2f} USD")
    print(f"ğŸª ç²å–åœ°é»ç¸½æ•¸ (åŒ…å«é‡è¤‡æ¢ç›®): {len(scraper.restaurants_data)} å®¶")  # æ›´æ–°æè¿°
    print(f"ğŸ”‘ ç¨ç‰¹åœ°é»ç¸½æ•¸: {len(scraper.processed_place_ids)} å®¶")  # æ›´æ–°æè¿°
    print(f"ğŸ¯ è¦†è“‹Birminghamå…¨å€åŸŸ: âœ…")

    print(f"\nğŸ“ˆ æœå°‹æ•ˆæœåˆ†æ:")
    print(f"- é æœŸæœ€å¤§åœ°é»æ•¸ (æ‰€æœ‰æœå°‹å€åŸŸçš„ä¸Šé™ç¸½å’Œ): {total_max_restaurants_per_search} å®¶")  # æ›´æ–°æè¿°
    print(f"- å¯¦éš›ç²å–ç¨ç‰¹åœ°é»æ•¸: {len(scraper.processed_place_ids)} å®¶")  # æ›´æ–°æè¿°
    efficiency = (
                             len(scraper.processed_place_ids) / total_max_restaurants_per_search) * 100 if total_max_restaurants_per_search > 0 else 0
    print(f"- æœå°‹æ•ˆç‡ (ç¨ç‰¹åœ°é»ä½”ç†è«–æœ€å¤§å€¼): {efficiency:.1f}%")  # æ›´æ–°æè¿°
    if efficiency < 50:
        print("ğŸ’¡ æ•ˆç‡è¼ƒä½å¯èƒ½æ˜¯å› ç‚ºå€åŸŸé‡ç–Šå°è‡´å¤§é‡é‡è¤‡ï¼Œé€™æ˜¯æ­£å¸¸ç¾è±¡ï¼Œå»é‡åŠŸèƒ½å·²ç¯€çœè²»ç”¨ã€‚")
    else:
        print("ğŸ‰ é«˜æ•ˆç‡æœå°‹ï¼ŒæˆåŠŸç²å–å¤§é‡ç¨ç‰¹åœ°é»ï¼")


if __name__ == "__main__":
    run_scraper_main()
